"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[7108],{40010:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>o,contentTitle:()=>s,default:()=>m,frontMatter:()=>t,metadata:()=>c,toc:()=>l});var a=n(85893),i=n(11151);const t={tags:["machine-learning","scikit-learn","model-selection","grid-search"]},s="Grid Search",c={id:"machine-learning/model-selection/grid-search",title:"Grid Search",description:"Grid Search is a method of optimizing model performance by traversing a given combination of hyperparameters.",source:"@site/docs/machine-learning/model-selection/grid-search.md",sourceDirName:"machine-learning/model-selection",slug:"/machine-learning/model-selection/grid-search",permalink:"/site/docs/machine-learning/model-selection/grid-search",draft:!1,unlisted:!1,tags:[{label:"machine-learning",permalink:"/site/docs/tags/machine-learning"},{label:"scikit-learn",permalink:"/site/docs/tags/scikit-learn"},{label:"model-selection",permalink:"/site/docs/tags/model-selection"},{label:"grid-search",permalink:"/site/docs/tags/grid-search"}],version:"current",frontMatter:{tags:["machine-learning","scikit-learn","model-selection","grid-search"]},sidebar:"machinelearningSidebar",previous:{title:"K-fold Cross-Validation",permalink:"/site/docs/machine-learning/model-selection/k-fold-cross-validation"},next:{title:"Learning Curve and Validation Curve",permalink:"/site/docs/machine-learning/model-selection/learning-and-validation-curve"}},o={},l=[{value:"Algorithm Principle",id:"algorithm-principle",level:2},{value:"Data Load and Preprocessing",id:"data-load-and-preprocessing",level:2},{value:"Grid Search Using Scikit-learn",id:"grid-search-using-sklearn",level:2}];function d(e){const r={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.h1,{id:"grid-search",children:"Grid Search"}),"\n",(0,a.jsx)(r.p,{children:"Grid Search is a method of optimizing model performance by traversing a given combination of hyperparameters."}),"\n",(0,a.jsxs)(r.p,{children:["There are two types of parameters in machine learning algorithms: one is the parameters learned from the training set, such as the weight parameters and bias parameters in logistic regression, and the other is ",(0,a.jsx)(r.strong,{children:"hyperparameter"}),", which requires manual setting. Certain parameters, such as the regularization coefficient or the depth of the decision tree."]}),"\n",(0,a.jsx)(r.p,{children:"Grid search can further help improve model performance by finding the best combination of hyperparameters."}),"\n",(0,a.jsx)(r.h2,{id:"algorithm-principle",children:"Algorithm Principle"}),"\n",(0,a.jsx)(r.p,{children:"The idea of grid search is very simple and belongs to the Brute Force algorithm: exhaust every combination of hyperparameters to evaluate the corresponding model performance, and then select the hyperparameters for model performance."}),"\n",(0,a.jsx)(r.h2,{id:"data-load-and-preprocessing",children:"Data Load and Preprocessing"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:'import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",\n                  header=None)\nX = df.iloc[:, 2:]\ny = df.iloc[:, 1]\nle = LabelEncoder()\ny = le.fit_transform(y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n'})}),"\n",(0,a.jsx)(r.h2,{id:"grid-search-using-sklearn",children:"Grid Search Using Scikit-learn"}),"\n",(0,a.jsx)(r.p,{children:"Create a pipeline object:"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:"from sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\n\npipe_svc = make_pipeline(StandardScaler(),\n                          SVC(random_state=1))\n"})}),"\n",(0,a.jsx)(r.p,{children:"Grid search for the one with the highest accuracy among all hyperparameter combinations (8 + 64 = 72 below):"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:"from sklearn.model_selection import GridSearchCV\n\nparam_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\nparam_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n               {'svc__C': param_range, 'svc__gamma': param_range, 'svc__kernel': ['rbf']}]\n\ngs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=10)\ngs.fit(X_train, y_train)\n"})}),"\n",(0,a.jsx)(r.p,{children:"The accuracy, parameters, and model calling of the optimal model obtained by grid search are as follows:"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:"print(gs.best_score_)\n# Output: 0.984615384615\n\nprint(gs.best_params_)\n# Output: {'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n\nclf = gs.best_estimator_\nclf.fit(X_train, y_train)\nprint('Test accuracy: {:.3f}'.format(clf.score(X_test, y_test)))\n# Output: Test accuracy: 0.974\n"})})]})}function m(e={}){const{wrapper:r}={...(0,i.a)(),...e.components};return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},11151:(e,r,n)=>{n.d(r,{Z:()=>c,a:()=>s});var a=n(67294);const i={},t=a.createContext(i);function s(e){const r=a.useContext(t);return a.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function c(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(t.Provider,{value:r},e.children)}}}]);