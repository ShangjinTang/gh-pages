"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[7645],{70240:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>r,toc:()=>l});var i=n(85893),a=n(11151);const s={tags:["machine-learning","holdout","model-selection"]},o="Holdout Validation",r={id:"machine-learning/model-selection/holdout",title:"Holdout Validation",description:"Holdout validation is a widely used model validation method that divides the data set into different sets, one part for training and the other holdout for testing.",source:"@site/docs/machine-learning/model-selection/holdout.md",sourceDirName:"machine-learning/model-selection",slug:"/machine-learning/model-selection/holdout",permalink:"/site/docs/machine-learning/model-selection/holdout",draft:!1,unlisted:!1,tags:[{label:"machine-learning",permalink:"/site/docs/tags/machine-learning"},{label:"holdout",permalink:"/site/docs/tags/holdout"},{label:"model-selection",permalink:"/site/docs/tags/model-selection"}],version:"current",frontMatter:{tags:["machine-learning","holdout","model-selection"]},sidebar:"machinelearningSidebar",previous:{title:"Linear discriminant analysis",permalink:"/site/docs/machine-learning/feature-selection/feature-extraction-lda"},next:{title:"K-fold Cross-Validation",permalink:"/site/docs/machine-learning/model-selection/k-fold-cross-validation"}},d={},l=[{value:"Datasets: Train-set and Test-set",id:"train-test",level:2},{value:"Datasets: Train-set, Validation-set and Test-set",id:"train-validation-test",level:2}];function h(e){const t={h1:"h1",h2:"h2",img:"img",p:"p",strong:"strong",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"holdout-validation",children:"Holdout Validation"}),"\n",(0,i.jsx)(t.p,{children:"Holdout validation is a widely used model validation method that divides the data set into different sets, one part for training and the other holdout for testing."}),"\n",(0,i.jsx)(t.h2,{id:"train-test",children:"Datasets: Train-set and Test-set"}),"\n",(0,i.jsxs)(t.p,{children:["For evaluating the generalization performance of machine learning models, a classic and popular method is holdout cross-validation. The holdout method divides the initial data set into separate ",(0,i.jsx)(t.strong,{children:"Train Set"})," and ",(0,i.jsx)(t.strong,{children:"Test Set"}),". The former is used for model training, and the latter is used to evaluate the generalization performance of the model. In a typical machine learning program, hyperparameters are constantly adjusted and compared to further improve the performance of predictions on unseen data. This process is called ",(0,i.jsx)(t.strong,{children:"Model Selection"}),", and it attempts to adjust the hyperparameters to the optimum."]}),"\n",(0,i.jsx)(t.p,{children:"However, if the same test set is reused during the model selection process, then the test set is not a true test set. The real test set should be invisible. If you keep trying to fit the test set, the test set is actually part of the training set."}),"\n",(0,i.jsx)(t.p,{children:"Despite this, many people still divide the data set into a test set and a training set, and then make model selection based on the performance of the test set. This is not a good machine learning approach."}),"\n",(0,i.jsx)(t.h2,{id:"train-validation-test",children:"Datasets: Train-set, Validation-set and Test-set"}),"\n",(0,i.jsxs)(t.p,{children:["A better approach to model selection is to split the data into three parts: ",(0,i.jsx)(t.strong,{children:"Train Set"}),", ",(0,i.jsx)(t.strong,{children:"Validation Set"}),", and ",(0,i.jsx)(t.strong,{children:"Test Set"}),". The training set is used to fit different models, and then model selection is made based on the model's performance on the validation set. During the entire training process, the test set is invisible and will not overfit the test set."]}),"\n",(0,i.jsx)(t.p,{children:"The figure below illustrates the concept of maintaining cross-validation, using the training set and validation set to repeatedly train and adjust the hyperparameters to optimal levels, and then use the test set to evaluate the generalization performance of the model:"}),"\n",(0,i.jsx)(t.img,{src:"https://image.szdev.com/images/2018/12/03/book-py_ml_2nd-06_02.png",width:"600"}),"\n",(0,i.jsx)(t.p,{children:"The disadvantage of the holdout method is that algorithm evaluation is sensitive to data partitioning. For different data partitioning ratios and different distributions, the evaluation results may be quite different."})]})}function c(e={}){const{wrapper:t}={...(0,a.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},11151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>o});var i=n(67294);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);