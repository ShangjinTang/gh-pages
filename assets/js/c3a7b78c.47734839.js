"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[5992],{29050:e=>{e.exports=JSON.parse('{"label":"model-selection","permalink":"/site/docs/tags/model-selection","allTagsPath":"/site/docs/tags","count":4,"items":[{"id":"machine-learning/model-selection/grid-search","title":"Grid Search","description":"Grid Search is a method of optimizing model performance by traversing a given combination of hyperparameters.","permalink":"/site/docs/machine-learning/model-selection/grid-search"},{"id":"machine-learning/model-selection/holdout","title":"Holdout Validation","description":"Holdout validation is a widely used model validation method that divides the data set into different sets, one part for training and the other holdout for testing.","permalink":"/site/docs/machine-learning/model-selection/holdout"},{"id":"machine-learning/model-selection/k-fold-cross-validation","title":"K-fold Cross-Validation","description":"K-Fold Cross-Validation is a model selection method that divides the initial sample into K folds (Folds), one fold is used as the data set, and the remaining K-1 folds are used as the training set. Repeat the above steps K times and combine the results to obtain the final evaluation result. K-fold cross-validation solves the shortcoming of holdout only dividing the data once to a certain extent.","permalink":"/site/docs/machine-learning/model-selection/k-fold-cross-validation"},{"id":"machine-learning/model-selection/learning-and-validation-curve","title":"Learning Curve and Validation Curve","description":"Drawing the learning curve and validation curve of the model is a commonly used debugging method. From it, you can intuitively see the performance of the model on the test set and verification set, and determine whether there are over-fitting or under-fitting problems. .","permalink":"/site/docs/machine-learning/model-selection/learning-and-validation-curve"}],"unlisted":false}')}}]);