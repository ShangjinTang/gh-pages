"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[8596],{70944:e=>{e.exports=JSON.parse('{"label":"feature-extraction","permalink":"/site/docs/tags/feature-extraction","allTagsPath":"/site/docs/tags","count":2,"items":[{"id":"machine-learning/feature-selection/feature-extraction-lda","title":"Linear discriminant analysis","description":"Linear Discriminant Analysis (LDA), as a feature extraction technology, can improve computational efficiency and prevent overfitting due to the curse of dimensionality. LDA is similar to PCA, except that the goal of PCA is to find the orthogonal component axes that maximize the variance in the data set, while the goal of LDA is to find the feature subspace that optimizes class separability.","permalink":"/site/docs/machine-learning/feature-selection/feature-extraction-lda"},{"id":"machine-learning/feature-selection/feature-extraction-pca","title":"Principal Component Analysis","description":"Similar to feature selection, we can use feature extraction to reduce the number of features in the dataset. The difference is that feature selection preserves the original features, while feature extraction transforms or projects the data into a new feature space. This article introduces Principal Component Analysis (PCA), which is an unsupervised linear transformation technology whose main features are feature extraction and dimensionality reduction.","permalink":"/site/docs/machine-learning/feature-selection/feature-extraction-pca"}],"unlisted":false}')}}]);